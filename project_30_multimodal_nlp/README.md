# Project 30: Multimodal NLP

## Overview
Connect vision and language with CLIP.

## Model
- **Type**: CLIP (ViT-B/32)
- **Parameters**: 400M
- **Difficulty**: ★★★★☆

## Use Cases
- Image-text matching
- Visual search
- Zero-shot classification

## Performance
- Zero-shot accuracy: 76%
- Cross-modal retrieval: 88%

## Run
```bash
pip install transformers torch
python train.py
```
